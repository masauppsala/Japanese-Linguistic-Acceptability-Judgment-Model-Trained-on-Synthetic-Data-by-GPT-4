{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "p5oIjaYpnhBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "FaLi7ggCD0LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "PKkY2tSYEknR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "Ga60P7bDGv0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "Jck2FVQ6G_MQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gb7J09pZAX12"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlp-waseda/roberta-large-japanese-seq512\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"nlp-waseda/roberta-large-japanese-seq512\", num_labels=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "qEefPLBIIfms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "# URLs of the raw CSV files on GitHub\n",
        "url_train = 'https://raw.githubusercontent.com/masauppsala/Synthetic-Japanese-Data-by-GPT-4/main/train_outdomain_synth_latest.csv'\n",
        "url_eval = 'https://raw.githubusercontent.com/masauppsala/Synthetic-Japanese-Data-by-GPT-4/main/eval_outdomain_synth_latest.csv'\n",
        "\n",
        "# Loading the datasets directly from GitHub into pandas DataFrames\n",
        "df_train = pd.read_csv(url_train)\n",
        "df_eval = pd.read_csv(url_eval)\n",
        "\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "df_train = shuffle(df_train, random_state=42).reset_index(drop=True)\n",
        "df_eval = shuffle(df_eval, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "from datasets import Dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['sentence'], padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "# Convert DataFrame to Dataset\n",
        "dataset_train = Dataset.from_pandas(df_train)\n",
        "dataset_eval = Dataset.from_pandas(df_eval)\n",
        "\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenized_train = dataset_train.map(tokenize_function, batched=True)\n",
        "tokenized_eval = dataset_eval.map(tokenize_function, batched=True)\n",
        "\n",
        "\n",
        "def format_dataset(dataset):\n",
        "    return dataset.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
        "\n",
        "# Format the datasets\n",
        "formatted_train_dataset = format_dataset(tokenized_train)\n",
        "formatted_eval_dataset = format_dataset(tokenized_eval)\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "oGDTda0pKWLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Extract labels from the formatted dataset\n",
        "train_labels = formatted_train_dataset[\"labels\"]\n",
        "\n",
        "# Count the occurrences of each label\n",
        "label_counts = Counter(train_labels)\n",
        "\n",
        "# Print the counts\n",
        "print(label_counts)\n"
      ],
      "metadata": {
        "id": "6Z0O46IMa2e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the total number of instances in the training dataset\n",
        "total_instances = len(train_labels)\n",
        "\n",
        "# Compute the weight for class 0 by taking the inverse of its count, scaling it by the total number of instances, and normalizing\n",
        "weight_for_0 = (1 / label_counts[0]) * (total_instances) / 2.0\n",
        "\n",
        "# Compute the weight for class 1 similarly to class 0\n",
        "weight_for_1 = (1 / label_counts[1]) * (total_instances) / 2.0\n",
        "\n",
        "# Create a dictionary to store the computed class weights\n",
        "class_weights = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "# Print the dictionary containing class weights to verify the calculations\n",
        "print(class_weights)"
      ],
      "metadata": {
        "id": "W423ztj0sKBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "import torch\n",
        "\n",
        "# Define training arguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate=5e-5,\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=10,  # Reduced from 5 to prevent overfitting\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=32,\n",
        "    warmup_steps=300,\n",
        "    weight_decay=0.02,  # Increased for regularization\n",
        "    logging_dir='./logs',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    save_total_limit=1,\n",
        "    lr_scheduler_type='linear',\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "# Define a custom Trainer class to use our specific loss function incorporating class weights\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=torch.tensor([class_weights[0], class_weights[1]], device=logits.device))\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Create a Custom Trainer\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=formatted_train_dataset,\n",
        "    eval_dataset=formatted_eval_dataset,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "zU40_2prclY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, load_metric\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, matthews_corrcoef\n",
        "\n",
        "url_test = 'https://raw.githubusercontent.com/masauppsala/Synthetic-Japanese-Data-by-GPT-4/main/originaltestcorpora.csv'\n",
        "\n",
        "df_test = pd.read_csv(url_test, delimiter=',')\n",
        "\n",
        "dataset_test = Dataset.from_pandas(df_test)\n",
        "\n",
        "tokenized_test = dataset_test.map(tokenize_function, batched=True)\n",
        "\n",
        "# Convert to pandas DataFrame for analysis\n",
        "formatted_test_dataset = tokenized_test.to_pandas()\n",
        "\n",
        "# List of syntactic phenomena to analyze\n",
        "syntactic_phenomena = ['simple', 'Arg. Str.', 'ellipsis', 'filler-gap', 'control/raising', 'island effects', 'NPI/NCI', 'verbal agr.', 'binding', 'morphology', 'nominal structure', 'quantifier']\n",
        "\n",
        "# Results list to store metrics for each phenomenon\n",
        "results = []\n",
        "\n",
        "def get_predictions_for_subset(subset_df):\n",
        "    # Convert the subset DataFrame back to a Dataset for prediction\n",
        "    formatted_subset_dataset = Dataset.from_pandas(subset_df)\n",
        "\n",
        "    # Get predictions using your model's method\n",
        "    predictions = trainer.predict(formatted_subset_dataset)\n",
        "    pred_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "    return pred_labels, predictions.label_ids\n",
        "\n",
        "# For overall accuracy and MCC\n",
        "overall_pred_labels, overall_true_labels = get_predictions_for_subset(formatted_test_dataset)\n",
        "overall_accuracy = accuracy_score(overall_true_labels, overall_pred_labels)\n",
        "overall_mcc = matthews_corrcoef(overall_true_labels, overall_pred_labels)\n",
        "\n",
        "for phenomenon in syntactic_phenomena:\n",
        "    if phenomenon in formatted_test_dataset.columns:\n",
        "        filtered_dataset = formatted_test_dataset[formatted_test_dataset[phenomenon] == True]\n",
        "        pred_labels, true_labels = get_predictions_for_subset(filtered_dataset)\n",
        "\n",
        "        # Calculate and store accuracy\n",
        "        accuracy = accuracy_score(true_labels, pred_labels)\n",
        "\n",
        "        # Calculate and store MCC\n",
        "        mcc = matthews_corrcoef(true_labels, pred_labels)\n",
        "\n",
        "        # Append results\n",
        "        results.append({\n",
        "            'Phenomenon': phenomenon,\n",
        "            'Accuracy': accuracy,\n",
        "            'MCC': mcc\n",
        "        })\n",
        "\n",
        "# Add overall accuracy and MCC to the results\n",
        "results.append({\n",
        "    'Phenomenon': 'Overall',\n",
        "    'Accuracy': overall_accuracy,\n",
        "    'MCC': overall_mcc\n",
        "})\n",
        "\n",
        "# Create DataFrame and save as CSV\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n",
        "results_df.to_csv('analysis_results.csv', index=False)\n"
      ],
      "metadata": {
        "id": "hnlBwkwtg9FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, load_metric\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
        "\n",
        "# List of syntactic phenomena to analyze\n",
        "syntactic_phenomena = ['simple', 'Arg. Str.', 'ellipsis', 'filler-gap', 'control/raising', 'island effects', 'NPI/NCI', 'verbal agr.', 'binding', 'morphology', 'nominal structure', 'quantifier']\n",
        "\n",
        "# Results list to store metrics for each phenomenon\n",
        "results = []\n",
        "\n",
        "def get_predictions_for_subset(subset_df):\n",
        "    # Convert the subset DataFrame back to a Dataset for prediction\n",
        "    formatted_subset_dataset = Dataset.from_pandas(subset_df)\n",
        "\n",
        "    # Get predictions\n",
        "    predictions = trainer.predict(formatted_subset_dataset)\n",
        "    pred_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "    return pred_labels, predictions.label_ids\n",
        "\n",
        "for phenomenon in syntactic_phenomena:\n",
        "    if phenomenon in formatted_test_dataset.columns:\n",
        "        filtered_dataset = formatted_test_dataset[formatted_test_dataset[phenomenon] == True]\n",
        "        pred_labels, true_labels = get_predictions_for_subset(filtered_dataset)\n",
        "\n",
        "        # Get the full classification report\n",
        "        print(f\"Classification Report for {phenomenon}:\")\n",
        "        class_report = classification_report(true_labels, pred_labels)\n",
        "        print(class_report)\n",
        "\n",
        "        # Extract metrics from the report dictionary\n",
        "        class_report_dict = classification_report(true_labels, pred_labels, output_dict=True)\n",
        "        accuracy = class_report_dict['accuracy']\n",
        "        recallmacro = class_report_dict['macro avg']['recall']  # Adjust as needed\n",
        "        f1macro = class_report_dict['macro avg']['f1-score']\n",
        "        recallweighted = class_report_dict['weighted avg']['recall']  # Adjust as needed\n",
        "        f1weighted = class_report_dict['weighted avg']['f1-score']\n",
        "           # Adjust as needed\n",
        "\n",
        "        roc_auc = \"N/A\"\n",
        "        if len(set(true_labels)) == 2:\n",
        "            roc_auc = roc_auc_score(true_labels, pred_labels)\n",
        "\n",
        "        # Append results\n",
        "        results.append({\n",
        "            'Phenomenon': phenomenon,\n",
        "            'Accuracy': accuracy,\n",
        "            'Recall(macro)': recallmacro,\n",
        "            'Recall(weighted)': recallweighted,\n",
        "            'F1-Score(macro)': f1macro,\n",
        "            'F1-Score(weighted)': f1weighted,\n",
        "            'ROC AUC': roc_auc\n",
        "        })\n",
        "\n",
        "# Create DataFrame and save as CSV\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('analysis_results.csv', index=False)\n"
      ],
      "metadata": {
        "id": "iqP_k3q-FlKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# Obtain overall predictions for the entire formatted_test_dataset\n",
        "overall_pred_labels, overall_true_labels = get_predictions_for_subset(formatted_test_dataset)\n",
        "\n",
        "# Calculate overall metrics and get it as a dictionary\n",
        "overall_report_dict = classification_report(overall_true_labels, overall_pred_labels, output_dict=True)\n",
        "\n",
        "# Convert dictionary to DataFrame\n",
        "overall_report_df = pd.DataFrame(overall_report_dict).transpose()\n",
        "\n",
        "print(overall_report_df)\n",
        "# Save DataFrame to CSV\n",
        "overall_report_df.to_csv('overall_performance_report.csv', index=True)"
      ],
      "metadata": {
        "id": "ydQ9o_r9LGqk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}